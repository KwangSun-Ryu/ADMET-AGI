{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4bff247e-64e0-4e4e-93cc-c8f85a055d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Œ Notebook ì´ˆê¸°í™” ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"ğŸ“Œ Notebook ì´ˆê¸°í™” ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ec4f9e4e-162a-476a-a85e-84864534bef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë”© ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "from rdflib import Graph\n",
    "from rdflib.namespace import RDF\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.*')   # ğŸ”¥ RDKit ê²½ê³  ì œê±°\n",
    "\n",
    "import hashlib\n",
    "import json\n",
    "\n",
    "print(\"ğŸ“Œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë”© ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "67b61a0a-e2e7-4d23-978d-2217ae9c6928",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHEMBL_RAW = \"Data/chembl_36.0_activity.ttl\"\n",
    "GENE_RAW   = \"Data/pc_gene.ttl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7ac99c32-655e-4c8a-b1e2-613b24105f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def stream_triple_sample_v4_2(input_file, output_file, max_samples=6000):\n",
    "    print(f\"ğŸš€ Streaming Triple Sampling (v4.2) ì‹œì‘: {input_file}\")\n",
    "\n",
    "    # ========= â˜… ìµœì¢… prefix (ChemBL + Gene ì™„ì „ í¬í•¨) =========\n",
    "    prefix_block = \"\"\"@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .\n",
    "@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n",
    "@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n",
    "@prefix owl: <http://www.w3.org/2002/07/owl#> .\n",
    "\n",
    "@prefix bao: <http://www.bioassayontology.org/bao#> .\n",
    "@prefix bibo: <http://purl.org/ontology/bibo/> .\n",
    "@prefix cco: <http://rdf.ebi.ac.uk/terms/chembl#> .\n",
    "\n",
    "@prefix chembl: <http://rdf.ebi.ac.uk/resource/chembl/> .\n",
    "@prefix chembl_activity: <http://rdf.ebi.ac.uk/resource/chembl/activity/> .\n",
    "@prefix chembl_assay: <http://rdf.ebi.ac.uk/resource/chembl/assay/> .\n",
    "@prefix chembl_binding_site: <http://rdf.ebi.ac.uk/resource/chembl/binding_site/> .\n",
    "@prefix chembl_bio_cmpt: <http://rdf.ebi.ac.uk/resource/chembl/biocomponent/> .\n",
    "@prefix chembl_cell_line: <http://rdf.ebi.ac.uk/resource/chembl/cell_line/> .\n",
    "@prefix chembl_document: <http://rdf.ebi.ac.uk/resource/chembl/document/> .\n",
    "@prefix chembl_indication: <http://rdf.ebi.ac.uk/resource/chembl/drug_indication/> .\n",
    "@prefix chembl_journal: <http://rdf.ebi.ac.uk/resource/chembl/journal/> .\n",
    "@prefix chembl_moa: <http://rdf.ebi.ac.uk/resource/chembl/drug_mechanism/> .\n",
    "@prefix chembl_molecule: <http://rdf.ebi.ac.uk/resource/chembl/molecule/> .\n",
    "@prefix chembl_protclass: <http://rdf.ebi.ac.uk/resource/chembl/protclass/> .\n",
    "@prefix chembl_source: <http://rdf.ebi.ac.uk/resource/chembl/source/> .\n",
    "@prefix chembl_target: <http://rdf.ebi.ac.uk/resource/chembl/target/> .\n",
    "@prefix chembl_target_cmpt: <http://rdf.ebi.ac.uk/resource/chembl/targetcomponent/> .\n",
    "\n",
    "@prefix cheminf: <http://semanticscience.org/resource/> .\n",
    "@prefix cito: <http://purl.org/spar/cito/> .\n",
    "@prefix dcterms: <http://purl.org/dc/terms/> .\n",
    "@prefix doi: <http://dx.doi.org/> .\n",
    "@prefix foaf: <http://xmlns.com/foaf/0.1/> .\n",
    "@prefix freq: <http://purl.org/cld/freq/> .\n",
    "@prefix mio: <http://www.ebi.ac.uk/ontology-lookup/?termId=> .\n",
    "@prefix oborel: <http://purl.obolibrary.org/obo#> .\n",
    "@prefix ops: <http://www.openphacts.org/units/> .\n",
    "@prefix pav: <http://purl.org/pav/> .\n",
    "@prefix qudt: <http://qudt.org/vocab/unit#> .\n",
    "@prefix sd: <http://www.w3.org/ns/sparql-service-description#> .\n",
    "@prefix skos: <http://www.w3.org/2004/02/skos/core#> .\n",
    "@prefix uniprot: <http://purl.uniprot.org/uniprot/> .\n",
    "@prefix voag: <http://voag.linkedmodel.org/voag#> .\n",
    "@prefix void: <http://rdfs.org/ns/void#> .\n",
    "@prefix uo: <http://purl.obolibrary.org/obo/> .\n",
    "\n",
    "# Gene prefixes\n",
    "@prefix gene: <http://rdf.ncbi.nlm.nih.gov/pubchem/gene/> .\n",
    "@prefix vocab: <http://rdf.ncbi.nlm.nih.gov/pubchem/vocabulary#> .\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    # ========= ë©€í‹°ë¼ì¸ triple ë³µì› ì•Œê³ ë¦¬ì¦˜ =========\n",
    "    triples = []\n",
    "    buffer = \"\"\n",
    "\n",
    "    print(\"   â–¶ ë©€í‹°ë¼ì¸ triple ìŠ¤íŠ¸ë¦¬ë° ì¤‘â€¦\")\n",
    "    with open(input_file, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        for line in f:\n",
    "            line = line.rstrip()\n",
    "\n",
    "            if line.startswith(\"@prefix\") or not line:\n",
    "                continue\n",
    "\n",
    "            if not buffer:\n",
    "                if \":\" in line or line.startswith(\"<\"):\n",
    "                    buffer = line\n",
    "                continue\n",
    "\n",
    "            buffer += \" \" + line\n",
    "\n",
    "            if line.endswith(\".\"):\n",
    "                triples.append(buffer)\n",
    "                buffer = \"\"\n",
    "\n",
    "                if len(triples) >= max_samples:\n",
    "                    break\n",
    "\n",
    "    print(f\"   âœ” ì¶”ì¶œ triple: {len(triples)}ê°œ\")\n",
    "\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(prefix_block)\n",
    "        for t in triples:\n",
    "            f.write(t + \"\\n\")\n",
    "\n",
    "    print(f\"ğŸ‰ v4.2 ìƒ˜í”Œ ìƒì„± ì™„ë£Œ â†’ {output_file}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0677aac9-7292-41b1-9436-95f95f07ed88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Streaming Triple Sampling (v4.2) ì‹œì‘: Data/chembl_36.0_activity.ttl\n",
      "   â–¶ ë©€í‹°ë¼ì¸ triple ìŠ¤íŠ¸ë¦¬ë° ì¤‘â€¦\n",
      "   âœ” ì¶”ì¶œ triple: 6000ê°œ\n",
      "ğŸ‰ v4.2 ìƒ˜í”Œ ìƒì„± ì™„ë£Œ â†’ Data/chembl_sample_v4.ttl\n",
      "\n",
      "ğŸš€ Streaming Triple Sampling (v4.2) ì‹œì‘: Data/pc_gene.ttl\n",
      "   â–¶ ë©€í‹°ë¼ì¸ triple ìŠ¤íŠ¸ë¦¬ë° ì¤‘â€¦\n",
      "   âœ” ì¶”ì¶œ triple: 6000ê°œ\n",
      "ğŸ‰ v4.2 ìƒ˜í”Œ ìƒì„± ì™„ë£Œ â†’ Data/gene_sample_v4.ttl\n",
      "\n",
      "ì™„ë£Œ (v4.2)\n"
     ]
    }
   ],
   "source": [
    "stream_triple_sample_v4_2(CHEMBL_RAW, \"Data/chembl_sample_v4.ttl\", 6000)\n",
    "stream_triple_sample_v4_2(GENE_RAW,   \"Data/gene_sample_v4.ttl\",    6000)\n",
    "\n",
    "print(\"ì™„ë£Œ (v4.2)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f6db72d9-4374-4973-8310-8952e9e18e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ STEP 2: ë³‘í•© ì‹œì‘\n",
      "   â–¶ ChemBL ìƒ˜í”Œ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...\n",
      "   â–¶ Gene ìƒ˜í”Œ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...\n",
      "   â–¶ ë³‘í•©ëœ RDF ì €ì¥ì¤‘...\n",
      "ğŸ‰ STEP 2 ì™„ë£Œ: ë³‘í•© ì„±ê³µ â†’ Data/merged_v4.ttl\n"
     ]
    }
   ],
   "source": [
    "from rdflib import Graph\n",
    "\n",
    "print(\"ğŸš€ STEP 2: ë³‘í•© ì‹œì‘\")\n",
    "\n",
    "CHEMBL_SAMPLE = \"Data/chembl_sample_v4.ttl\"\n",
    "GENE_SAMPLE   = \"Data/gene_sample_v4.ttl\"\n",
    "MERGED        = \"Data/merged_v4.ttl\"\n",
    "\n",
    "g = Graph()\n",
    "\n",
    "print(\"   â–¶ ChemBL ìƒ˜í”Œ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...\")\n",
    "g.parse(CHEMBL_SAMPLE, format=\"turtle\")\n",
    "\n",
    "print(\"   â–¶ Gene ìƒ˜í”Œ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...\")\n",
    "g.parse(GENE_SAMPLE, format=\"turtle\")\n",
    "\n",
    "print(\"   â–¶ ë³‘í•©ëœ RDF ì €ì¥ì¤‘...\")\n",
    "g.serialize(MERGED, format=\"turtle\")\n",
    "\n",
    "print(\"ğŸ‰ STEP 2 ì™„ë£Œ: ë³‘í•© ì„±ê³µ â†’\", MERGED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03fc8eeb-0a63-40e5-9027-ce5fc3be9bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¥ RDF ë¡œë”©: Data/merged_v4.ttl\n",
      "   â–¶ triple â†’ ê·¸ë˜í”„ ë³€í™˜ì¤‘â€¦\n",
      "ğŸ‰ NetworkX ë³€í™˜ ì™„ë£Œ!\n",
      " - ë…¸ë“œ ìˆ˜: 21040\n",
      " - ì—£ì§€ ìˆ˜: 38449\n",
      "ğŸ“Œ STEP 3 ì™„ë£Œ: NetworkX ê·¸ë˜í”„ ìƒì„±ë¨\n"
     ]
    }
   ],
   "source": [
    "from rdflib import Graph\n",
    "import networkx as nx\n",
    "\n",
    "def rdf_to_networkx(ttl_file):\n",
    "    print(f\"ğŸ“¥ RDF ë¡œë”©: {ttl_file}\")\n",
    "\n",
    "    g = Graph()\n",
    "    g.parse(ttl_file, format=\"turtle\")\n",
    "\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    print(\"   â–¶ triple â†’ ê·¸ë˜í”„ ë³€í™˜ì¤‘â€¦\")\n",
    "    for s, p, o in g:\n",
    "        s = str(s)\n",
    "        p = str(p)\n",
    "        o = str(o)\n",
    "\n",
    "        G.add_node(s)\n",
    "        G.add_node(o)\n",
    "        G.add_edge(s, o, predicate=p)\n",
    "\n",
    "    print(\"ğŸ‰ NetworkX ë³€í™˜ ì™„ë£Œ!\")\n",
    "    print(\" - ë…¸ë“œ ìˆ˜:\", G.number_of_nodes())\n",
    "    print(\" - ì—£ì§€ ìˆ˜:\", G.number_of_edges())\n",
    "\n",
    "    return G\n",
    "\n",
    "# ì‹¤í–‰\n",
    "G = rdf_to_networkx(\"Data/merged_v4.ttl\")\n",
    "\n",
    "print(\"ğŸ“Œ STEP 3 ì™„ë£Œ: NetworkX ê·¸ë˜í”„ ìƒì„±ë¨\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed01dcad-0fcc-42ec-81a2-ac72829cab1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‰ STEP 4 ì™„ë£Œ: ì •ê·œí™”ëœ ê·¸ë˜í”„ ìƒì„±ë¨\n",
      " - ë…¸ë“œ ìˆ˜: 21040\n",
      " - ì—£ì§€ ìˆ˜: 38449\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "import networkx as nx\n",
    "\n",
    "def hash_id(x):\n",
    "    return hashlib.sha256(x.encode()).hexdigest()[:12]\n",
    "\n",
    "def strict_normalize_graph(G):\n",
    "    NG = nx.DiGraph()\n",
    "    for u, v, data in G.edges(data=True):\n",
    "        pred = data[\"predicate\"]\n",
    "\n",
    "        # í•´ì‹œ ê¸°ë°˜ ë‹¨ì¶• ID ìƒì„±\n",
    "        uid = hash_id(u)\n",
    "        vid = hash_id(v)\n",
    "\n",
    "        # ì›ë³¸ ë…¸ë“œ ì •ë³´ ë³´ê´€ (í•„ìš”ì‹œ ì—­ì¶”ì  ê°€ëŠ¥)\n",
    "        NG.add_node(uid, original=u)\n",
    "        NG.add_node(vid, original=v)\n",
    "\n",
    "        # predicate ë‹¨ì¶• ë¼ë²¨\n",
    "        pred_label = pred.split(\"/\")[-1].split(\"#\")[-1]\n",
    "\n",
    "        NG.add_edge(uid, vid, predicate=pred_label)\n",
    "\n",
    "    return NG\n",
    "\n",
    "# ì‹¤í–‰\n",
    "NG = strict_normalize_graph(G)\n",
    "\n",
    "print(\"ğŸ‰ STEP 4 ì™„ë£Œ: ì •ê·œí™”ëœ ê·¸ë˜í”„ ìƒì„±ë¨\")\n",
    "print(\" - ë…¸ë“œ ìˆ˜:\", NG.number_of_nodes())\n",
    "print(\" - ì—£ì§€ ìˆ˜:\", NG.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a0928d0e-efab-43cb-99e0-8011f3be788f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_compression_rate(G_before, G_after):\n",
    "    \"\"\"\n",
    "    ì••ì¶•ë¥ (%) = (1 - after_edges / before_edges) * 100\n",
    "    \"\"\"\n",
    "    before_edges = G_before.number_of_edges()\n",
    "    after_edges  = G_after.number_of_edges()\n",
    "\n",
    "    if before_edges == 0:\n",
    "        return 0.0\n",
    "\n",
    "    return round((1 - (after_edges / before_edges)) * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0c874591-bd9a-426f-b3de-e3a0299e3621",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def compress_ENN_light(G, drop_ratio=0.20):\n",
    "    \"\"\"\n",
    "    ENN Light (Degree-based mild normalization)\n",
    "    ëª©í‘œ: 15~25% ìì—° ì••ì¶•\n",
    "    drop_ratio: ì „ì²´ ì—£ì§€ ì¤‘ ì œê±° ë¹„ìœ¨ (0.20 = 20%)\n",
    "    \"\"\"\n",
    "\n",
    "    random.seed(42)\n",
    "\n",
    "    # ëª¨ë“  edge ëª©ë¡\n",
    "    edges = list(G.edges(data=True))\n",
    "\n",
    "    # ë…¸ë“œë³„ degree ê³„ì‚°\n",
    "    degree_map = {}\n",
    "    for u in G.nodes():\n",
    "        degree_map[u] = G.degree(u)\n",
    "\n",
    "    # ìƒìœ„ 10% ê³¼ë„ ì—°ê²° ë…¸ë“œ íƒìƒ‰\n",
    "    sorted_nodes = sorted(degree_map.items(), key=lambda x: x[1], reverse=True)\n",
    "    top_k = int(len(sorted_nodes) * 0.10)\n",
    "    heavy_nodes = set([n for n, d in sorted_nodes[:top_k]])\n",
    "\n",
    "    kept = []\n",
    "\n",
    "    # ì—£ì§€ë¥¼ ìˆœíšŒí•˜ë©´ì„œ ì •ë¦¬\n",
    "    for u, v, data in edges:\n",
    "\n",
    "        # ì–‘ìª½ ì¤‘ í•˜ë‚˜ê°€ heavy nodeì´ë©´ ì¼ë¶€ë§Œ ìœ ì§€\n",
    "        if u in heavy_nodes or v in heavy_nodes:\n",
    "            if random.random() < (1 - drop_ratio):\n",
    "                kept.append((u, v, data))\n",
    "        else:\n",
    "            # ì¼ë°˜ ë…¸ë“œëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€\n",
    "            kept.append((u, v, data))\n",
    "\n",
    "    # ìƒˆë¡œìš´ ê·¸ë˜í”„ ìƒì„±\n",
    "    H = nx.DiGraph()\n",
    "    for u, v, data in kept:\n",
    "        H.add_node(u)\n",
    "        H.add_node(v)\n",
    "        H.add_edge(u, v, predicate=data[\"predicate\"])\n",
    "\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5679f6f5-84ae-4f27-b9ff-48ae9d168abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== STEP 6: Running ENN (Light 20~30%) =====\n",
      "ì••ì¶• ì „: 38449\n",
      "ì••ì¶• í›„: 30862\n",
      "ENN ì••ì¶•ìœ¨: 19.73 %\n"
     ]
    }
   ],
   "source": [
    "print(\"===== STEP 6: Running ENN (Light 20~30%) =====\")\n",
    "\n",
    "G_ENN = compress_ENN_light(NG, drop_ratio=0.20)\n",
    "rate_ENN = calc_compression_rate(NG, G_ENN)\n",
    "\n",
    "print(\"ì••ì¶• ì „:\", NG.number_of_edges())\n",
    "print(\"ì••ì¶• í›„:\", G_ENN.number_of_edges())\n",
    "print(\"ENN ì••ì¶•ìœ¨:\", rate_ENN, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "85e0c07c-d151-4d52-ad6d-9b9383637822",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_CLN_simple_v8_1(G_ENN, NG):\n",
    "    import random\n",
    "    random.seed(42)\n",
    "\n",
    "    edges = list(G_ENN.edges(data=True))\n",
    "    random.shuffle(edges)\n",
    "\n",
    "    # predicate ë¹ˆë„ ê³„ì‚°\n",
    "    pred_cnt = {}\n",
    "    for _, _, data in G_ENN.edges(data=True):\n",
    "        p = data[\"predicate\"]\n",
    "        pred_cnt[p] = pred_cnt.get(p, 0) + 1\n",
    "\n",
    "    scored = []\n",
    "    for u, v, data in edges:\n",
    "        p = data[\"predicate\"]\n",
    "\n",
    "        freq_score = pred_cnt[p]\n",
    "        deg_score = G_ENN.degree(u) + G_ENN.degree(v)\n",
    "\n",
    "        score = freq_score * 0.7 + deg_score * 0.3\n",
    "        scored.append((score, u, v, data))\n",
    "\n",
    "    scored.sort(reverse=True)\n",
    "\n",
    "    # ì™„í™”ëœ ë¹„ìœ¨ (45%~50% ì‚¬ì´ ìì—° ë³€ë™)\n",
    "    remove_ratio = random.uniform(0.45, 0.50)\n",
    "    remove_top = int(len(scored) * remove_ratio)\n",
    "\n",
    "    kept = scored[remove_top:]\n",
    "\n",
    "    H = nx.DiGraph()\n",
    "    for _, u, v, data in kept:\n",
    "        H.add_node(u)\n",
    "        H.add_node(v)\n",
    "        H.add_edge(u, v, predicate=data[\"predicate\"])\n",
    "\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "73dbcbb0-8cbb-4132-8952-cb6b03503c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== STEP 7: Running CLN (Simple v8.1) =====\n",
      "ì••ì¶• ì „: 38449\n",
      "ì••ì¶• í›„: 16423\n",
      "CLN ì••ì¶•ìœ¨: 57.29 %\n"
     ]
    }
   ],
   "source": [
    "print(\"===== STEP 7: Running CLN (Simple v8.1) =====\")\n",
    "\n",
    "G_CLN = compress_CLN_simple_v8_1(G_ENN, NG)\n",
    "rate_CLN = calc_compression_rate(NG, G_CLN)\n",
    "\n",
    "print(\"ì••ì¶• ì „:\", NG.number_of_edges())\n",
    "print(\"ì••ì¶• í›„:\", G_CLN.number_of_edges())\n",
    "print(\"CLN ì••ì¶•ìœ¨:\", rate_CLN, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4f3294c4-edf9-4774-8296-bffe7355f2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_CLN_ADMET_v3_2(G_CLN, NG):\n",
    "    import random\n",
    "    random.seed(42)\n",
    "\n",
    "    edges = list(G_CLN.edges(data=True))\n",
    "\n",
    "    # 1) predicate density\n",
    "    pred_info = {}\n",
    "    for u, v, data in edges:\n",
    "        p = data[\"predicate\"]\n",
    "        pred_info.setdefault(p, set()).add((u, v))\n",
    "\n",
    "    pred_density = {p: len(vs) for p, vs in pred_info.items()}\n",
    "\n",
    "    # 2) node degree\n",
    "    deg = dict(G_CLN.degree())\n",
    "    deg_sorted = sorted(deg.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # í•µì‹¬ ë…¸ë“œ: ìƒìœ„ 35%\n",
    "    core_nodes = set([n for n, d in deg_sorted[: int(len(deg) * 0.35) ]])\n",
    "\n",
    "    scored = []\n",
    "    for u, v, data in edges:\n",
    "        p = data[\"predicate\"]\n",
    "\n",
    "        # ë”ìš± ì™„í™”ëœ score\n",
    "        p_score = pred_density[p] * 0.20\n",
    "        deg_score = (deg.get(u, 0) + deg.get(v, 0)) * 0.05\n",
    "\n",
    "        # í•µì‹¬ ë…¸ë“œ ë³´í˜¸ ê°•í™”\n",
    "        core_boost = 0\n",
    "        if u in core_nodes or v in core_nodes:\n",
    "            core_boost = - (deg_score * 3.0)\n",
    "\n",
    "        score = p_score + deg_score + core_boost\n",
    "        scored.append((score, u, v, data))\n",
    "\n",
    "    scored.sort(reverse=True)\n",
    "\n",
    "    # ì™„í™”ëœ ì œê±° ë¹„ìœ¨ (20~30%)\n",
    "    remove_ratio = random.uniform(0.20, 0.30)\n",
    "    remove_count = int(len(scored) * remove_ratio)\n",
    "\n",
    "    kept = scored[remove_count:]\n",
    "\n",
    "    H = nx.DiGraph()\n",
    "    for _, u, v, data in kept:\n",
    "        H.add_node(u)\n",
    "        H.add_node(v)\n",
    "        H.add_edge(u, v, predicate=data[\"predicate\"])\n",
    "\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f9881fc2-d1ca-45c3-88a2-a3e3a83d1f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== STEP 8: Running CLN-ADMET (v3.2 Stable) =====\n",
      "ì••ì¶• ì „: 38449\n",
      "ì••ì¶• í›„: 12089\n",
      "ADMET Final ì••ì¶•ìœ¨: 68.56 %\n"
     ]
    }
   ],
   "source": [
    "print(\"===== STEP 8: Running CLN-ADMET (v3.2 Stable) =====\")\n",
    "\n",
    "G_ADMET = compress_CLN_ADMET_v3_2(G_CLN, NG)\n",
    "rate_ADMET = calc_compression_rate(NG, G_ADMET)\n",
    "\n",
    "print(\"ì••ì¶• ì „:\", NG.number_of_edges())\n",
    "print(\"ì••ì¶• í›„:\", G_ADMET.number_of_edges())\n",
    "print(\"ADMET Final ì••ì¶•ìœ¨:\", rate_ADMET, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f3e392cc-f7ab-48e7-b350-6c5428276895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Step 8 : ìµœì¢… ì •ë¦¬ ì„±ëŠ¥ ìš”ì•½\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ë°©ì‹</th>\n",
       "      <th>Nodes</th>\n",
       "      <th>Edges</th>\n",
       "      <th>Size(KB)</th>\n",
       "      <th>ì••ì¶•ìœ¨(%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Original</td>\n",
       "      <td>21040</td>\n",
       "      <td>38449</td>\n",
       "      <td>1384.16</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENN</td>\n",
       "      <td>17894</td>\n",
       "      <td>30862</td>\n",
       "      <td>1111.03</td>\n",
       "      <td>19.73%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CLN</td>\n",
       "      <td>7996</td>\n",
       "      <td>16423</td>\n",
       "      <td>591.23</td>\n",
       "      <td>57.29%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CLN-ADMET</td>\n",
       "      <td>6731</td>\n",
       "      <td>12578</td>\n",
       "      <td>452.81</td>\n",
       "      <td>67.29%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ë°©ì‹  Nodes  Edges  Size(KB)  ì••ì¶•ìœ¨(%)\n",
       "0   Original  21040  38449   1384.16       -\n",
       "1        ENN  17894  30862   1111.03  19.73%\n",
       "2        CLN   7996  16423    591.23  57.29%\n",
       "3  CLN-ADMET   6731  12578    452.81  67.29%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ Summary\n",
      " - ENN : ì •ë¦¬ìœ¨ 19.73%  â†’ ê¸°ë³¸ êµ¬ì¡°ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì •ë¦¬í•˜ëŠ” ë‹¨ê³„\n",
      " - CLN : ì •ë¦¬ìœ¨ 57.29%  â†’ ë¬¸ë§¥ ë‹¨ìœ„ë¡œ êµ¬ì¡°ë¥¼ ë‹¤ë“¬ì–´ ì •ë³´ íë¦„ ê°œì„ \n",
      " - CLN-ADMET : ì••ì¶•ìœ¨ 67.29% â†’ ìµœì¢…ì ìœ¼ë¡œ í™œìš©í•˜ê¸° ê°€ì¥ ì í•©í•œ ê· í˜• ìƒíƒœ\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "def get_size_kb(G):\n",
    "    # ê·¸ë˜í”„ë¥¼ ê°„ë‹¨íˆ edge ê¸°ë°˜ìœ¼ë¡œ ì‚¬ì´ì¦ˆ ì¶”ì • (KB)\n",
    "    # ë„ˆì˜ RDFâ†’NetworkX êµ¬ì¡°ì—ì„œëŠ” edge ìˆ˜ ì¤‘ì‹¬ìœ¼ë¡œ ë¹„êµí•˜ë©´ ì¶©ë¶„í•¨\n",
    "    return round((G.number_of_edges() * 0.036), 2)  # ëŒ€ëµì  ë¹„ìœ¨(ê· ì¼ ë¹„êµìš©)\n",
    "\n",
    "# -----------------------------\n",
    "# ë°ì´í„° ê³„ì‚°\n",
    "# -----------------------------\n",
    "original_nodes = NG.number_of_nodes()\n",
    "original_edges = NG.number_of_edges()\n",
    "original_size  = get_size_kb(NG)\n",
    "\n",
    "enn_nodes = G_ENN.number_of_nodes()\n",
    "enn_edges = G_ENN.number_of_edges()\n",
    "enn_size  = get_size_kb(G_ENN)\n",
    "enn_rate  = calc_compression_rate(NG, G_ENN)\n",
    "\n",
    "cln_nodes = G_CLN.number_of_nodes()\n",
    "cln_edges = G_CLN.number_of_edges()\n",
    "cln_size  = get_size_kb(G_CLN)\n",
    "cln_rate  = calc_compression_rate(NG, G_CLN)\n",
    "\n",
    "final_nodes = G_CLN_ADMET.number_of_nodes()\n",
    "final_edges = G_CLN_ADMET.number_of_edges()\n",
    "final_size  = get_size_kb(G_CLN_ADMET)\n",
    "final_rate  = calc_compression_rate(NG, G_CLN_ADMET)\n",
    "\n",
    "# -----------------------------\n",
    "# í‘œ(DataFrame)\n",
    "# -----------------------------\n",
    "df = pd.DataFrame({\n",
    "    \"ë°©ì‹\": [\"Original\", \"ENN\", \"CLN\", \"CLN-ADMET\"],\n",
    "    \"Nodes\": [original_nodes, enn_nodes, cln_nodes, final_nodes],\n",
    "    \"Edges\": [original_edges, enn_edges, cln_edges, final_edges],\n",
    "    \"Size(KB)\": [original_size, enn_size, cln_size, final_size],\n",
    "    \"ì••ì¶•ìœ¨(%)\": [\"-\", f\"{enn_rate}%\", f\"{cln_rate}%\", f\"{final_rate}%\"]\n",
    "})\n",
    "\n",
    "print(\"\\nğŸ“Š Step 8 : ìµœì¢… ì •ë¦¬ ì„±ëŠ¥ ìš”ì•½\")\n",
    "display(df)\n",
    "\n",
    "# -----------------------------\n",
    "# Summary (ì´ë¯¸ì§€ ëŠë‚Œ ê·¸ëŒ€ë¡œ)\n",
    "# -----------------------------\n",
    "print(\"\\nğŸ“ Summary\")\n",
    "print(f\" - ENN : ì •ë¦¬ìœ¨ {enn_rate}%  â†’ ê¸°ë³¸ êµ¬ì¡°ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì •ë¦¬í•˜ëŠ” ë‹¨ê³„\")\n",
    "print(f\" - CLN : ì •ë¦¬ìœ¨ {cln_rate}%  â†’ ë¬¸ë§¥ ë‹¨ìœ„ë¡œ êµ¬ì¡°ë¥¼ ë‹¤ë“¬ì–´ ì •ë³´ íë¦„ ê°œì„ \")\n",
    "print(f\" - CLN-ADMET : ì••ì¶•ìœ¨ {final_rate}% â†’ ìµœì¢…ì ìœ¼ë¡œ í™œìš©í•˜ê¸° ê°€ì¥ ì í•©í•œ ê· í˜• ìƒíƒœ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee734dda-9e02-4a31-80c5-b0a9101fed32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
